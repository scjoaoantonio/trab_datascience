# ---------------------------------------------------
# ğŸ“¦ ImportaÃ§Ãµes de Bibliotecas e MÃ³dulos do Projeto
# ---------------------------------------------------
import streamlit as st
import pandas as pd

# ğŸ§© MÃ³dulos personalizados para anÃ¡lise de dados
import api as bsky                     # API personalizada para coleta e limpeza de dados do Bluesky
import utils.mining as mining         # MineraÃ§Ã£o de texto: sentimentos, tÃ³picos, etc.
import utils.arima_model as arima     # Modelagem preditiva com ARIMA
import utils.graph_utils as graph     # GrÃ¡ficos e visualizaÃ§Ãµes
import utils.patterns as patterns     # AnÃ¡lise de padrÃµes em posts
import utils.map as maps              # GeraÃ§Ã£o de mapas interativos

# ---------------------------------------------------
# ğŸ§‘â€ğŸ’» FunÃ§Ã£o Principal da PÃ¡gina de AnÃ¡lise por UsuÃ¡rio
# ---------------------------------------------------
def usersPage():
    st.title("Analisar Posts de um UsuÃ¡rio")

    # ğŸ”§ Inputs de configuraÃ§Ã£o da anÃ¡lise
    actor = st.text_input("Digite o @ do usuÃ¡rio:", value="nytimes.com", key="actor_input")
    limit = st.number_input("Quantidade de posts por iteraÃ§Ã£o:", min_value=1, max_value=100, value=100, key="limit_input")
    iterations = st.number_input("NÃºmero de iteraÃ§Ãµes:", min_value=1, value=100, key="iterations_input")
    forecast_days = st.radio("Quantidade de dias para previsÃ£o de engajamento:", (3, 7, 30), key="days_radio")
    
    language = st.radio("Escolha o idioma:", ('PortuguÃªs', 'InglÃªs'), key="language_radio")
    language_code = 'portuguese' if language == 'PortuguÃªs' else 'english'

    # â–¶ï¸ BotÃ£o para iniciar anÃ¡lise
    if st.button("Analisar", key="analyze_button"):
        if actor:
            bsky.nltkDownload()  # Garante que os dados do NLTK estÃ£o configurados corretamente
            st.write("Coletando dados...")

            # ğŸ“¥ Coleta os posts do usuÃ¡rio
            posts = bsky.collectPosts(actor, limit, iterations, language_code)

            if posts:
                st.write(f"Total de posts coletados: {len(posts)}")
                df = pd.DataFrame(posts)

                # ğŸ’¾ Permite download dos dados coletados
                st.write("### Baixar Dados como CSV")
                csv = df.to_csv(index=False)
                st.download_button(label="Baixar CSV", data=csv, file_name="dados_posts.csv", mime="text/csv")

                # â˜ï¸ GeraÃ§Ã£o de WordCloud
                st.write("### WordCloud das Palavras Mais Frequentes")
                graph.generate_wordcloud(df['tokens'])

                # ğŸ“Š DistribuiÃ§Ã£o das mÃ©tricas de engajamento
                st.write("### DistribuiÃ§Ã£o dos Valores")
                graph.distribution_values(df)

                # ğŸ”¥ AnÃ¡lise de correlaÃ§Ã£o entre variÃ¡veis
                st.write("### CorrelaÃ§Ã£o Entre os Atributos")
                graph.analyze_correlation(df)

                # ğŸŒŸ Destaque para os posts com maior engajamento
                st.write("### Posts com Maior Engajamento")
                top_posts = df.sort_values(by='total', ascending=False).head(5)
                for _, row in top_posts.iterrows():
                    st.write(f"**{row['author_displayName']}** (@{row['author_handle']}) - **Engajamento:** {row['total']}")
                    st.write(f"**Texto Original:** {row['texto_original']}")

                    # ğŸ–¼ï¸ Exibe imagens dos posts, se houver
                    embed = row.get("record", {}).get("embed", {}) if isinstance(row.get("record"), dict) else {}
                    if embed.get("$type") == "app.bsky.embed.images#view":
                        for image in embed.get("images", []):
                            image_url = image.get("fullsize", "")
                            if image_url:
                                st.image(image_url, caption="Imagem do Post", use_column_width=True)

                # ğŸ” AnÃ¡lise de padrÃµes nos posts (ex: tamanho do texto, horÃ¡rios, etc.)
                patterns.analyze_post_features(df)

                # ğŸ“ˆ PrÃ©-processa para anÃ¡lise temporal
                df['data_hora'] = pd.to_datetime(df['data_hora'])
                temporal_data = df.groupby(df['data_hora'].dt.date)['total'].sum()
                # st.line_chart(temporal_data)  # VocÃª pode ativar isso se quiser mostrar a linha do tempo

                # ğŸ“‰ PrevisÃ£o de engajamento com ARIMA
                st.write("### PrevisÃ£o de Engajamento para os PrÃ³ximos Dias")
                arima.train_arima(df, forecast_days)

                # ğŸ•’ RecomendaÃ§Ãµes com base nos melhores horÃ¡rios e tamanhos de post
                melhor_hora, melhor_dia, melhor_tamanho = arima.analyze_best_post(df)

                # ğŸ’¬ AnÃ¡lise de sentimentos, modelagem de tÃ³picos e geolocalizaÃ§Ã£o
                mining.analyzeSentiment(df)
                mining.topicModeling(df)
                mining.analyze_sentiment_by_state(df)
                maps.create_sentiment_map(df)

            else:
                st.error("Nenhum dado encontrado para o usuÃ¡rio informado.")
        else:
            st.error("Por favor, insira o @ do usuÃ¡rio.")
